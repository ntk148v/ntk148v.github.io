<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>prometheus on kiennt26's home</title><link>https://ntk148v.github.io/tags/prometheus/</link><description>Recent content in prometheus on kiennt26's home</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 05 May 2020 13:51:59 +0700</lastBuildDate><atom:link href="https://ntk148v.github.io/tags/prometheus/index.xml" rel="self" type="application/rss+xml"/><item><title>Ansitheus</title><link>https://ntk148v.github.io/posts/ansitheus/</link><pubDate>Tue, 05 May 2020 13:51:59 +0700</pubDate><guid>https://ntk148v.github.io/posts/ansitheus/</guid><description>Ansitheus = Ansible + Prometheus 1. Prometheus overview NOTE: Checkout the Prometheus official documentation.
Prometheus is an open-source systems monitoring &amp;amp; alerting toolkit originally built at SoundCloud.
1.1. Features a multi-dimensional data model with time series data identified by metric name &amp;amp; key/value pairs PromQL, a flexible query language to leverage this dimensionality no reliance on distributed storage; single server nodes are autonomous time series collection happens via a pull model over HTTP pushing time series is supported via an intermediary gateway targets are discovered via service discovery or static configuration multiple modes of graphing &amp;amp; dashboarding support 1.</description></item><item><title>Openstack Autoscaling New Approach</title><link>https://ntk148v.github.io/posts/openstack-autoscaling-new-approach/</link><pubDate>Mon, 19 Aug 2019 21:19:38 +0700</pubDate><guid>https://ntk148v.github.io/posts/openstack-autoscaling-new-approach/</guid><description>NOTE(kiennt): There is a legacy Faythe guideline. The new version is coming soon, check its repository for status.
This guide describes how to automatically scale out your Compute instances in response to heavy system usage. By combining with Prometheus pre-defined rules that consider factors such as CPU or memory usage, you can configure OpenStack Orchestration (Heat) to add and remove additional instances automatically, when they are needed.
1. The standard OpenStack Autoscaling approach Let&amp;rsquo;s talk about the standard OpenStack Autoscaling approach before goes to the new approach.</description></item></channel></rss>